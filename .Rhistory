diccionario_hogares[names(test_hogares)[names(test_hogares) %in% names(diccionario_hogares)]]
# 0.1.3 Variables relevantes Personas
# Etiquetas Variables Hogares:
# Diccionario variables
diccionario_personas <- c(
"P6020" = "Sexo",
"P6040" = "Edad",
"P6050" = "Jefe_hogar",
"P6090" = "SS_salud", #SS=Seguridad social
"P6100" = "Régimen_SS_salud",
"P6210" = "Nivel_educ",
"P6210s1" = "Grado_aprobado",
"P6240" = "Act_principal_SP", #SP=Semana pasada
"P6426" = "T_Tra_Emp", #Tiempo trabajado en la empresa (meses)
"P6430" = "Pos_tra_pri", #Posición trabajo principal
"P6510" = "Ing_HE", #Ingresos por horas extras
"P6545" = "Ing_Pr", #Ingresos por primas
"P6580" = "Ing_Bon", #Ingresos por Bonificaciones
"P6585s1" = "Sub_Ali", #Subsidio alimentación
"P6585s2" = "Sub_Trans",# Subsidio transporte
"P6585s3" = "Sub_Fam", # Subsidio familiar
"P6585s4" = "Sub_Edu",# Subsidio educativo
"P6590" = "Ing_esp_ali",# Ingresos en especie por alimentación
"P6600" = "Ing_esp_viv",# Ingresos en especie por vivienda
"P6610" = "Trans_emp", # Uso transporte de la empresa
"P6620" = "Ing_esp_otros",# Otros ingresos en especie
"P6630s1" = "Pri_serv_12m", # Prima de servicios últimos 12 meses
"P6630s2" = "Pri_nav_12m",# Prima de navidad últimos 12 meses
"P6630s3" = "Pri_vac_12m",# Prima de vacaciones últimos 12 meses
"P6630s4" = "Viat_per_12m", # Viáticos permanentes últimos 12 meses
"P6630s6" = "Bon_anual_12m",# Bonificaciones anuales últimos 12 meses
"P6800" = "Hras_sem_trab", # Horas trabajadas normalmente a la semana
"P6870" = "Tam_empresa",# Tamaño de la empresa donde trabaja
"P6920" = "Cot_pension",# Cotiza a fondo de pensiones
"P7040" = "Seg_trab_SP",# Tuvo segundo trabajo la semana pasada
"P7045" = "Hras_seg_trab",# Horas trabajadas en segundo trabajo
"P7050" = "Pos_tra_sec",  # Posición ocupacional en segundo trabajo
"P7090" = "Quiere_mas_horas",# Quiere trabajar más horas
"P7110" = "Diligencias_mas_horas",# Hizo diligencias para trabajar más horas
"P7120" = "Disp_mas_horas", # Disponible para trabajar más horas
"P7150" = "Dilig_camb_trab",# Hizo diligencias para cambiar de trabajo
"P7160" = "Disp_camb_trab", # Podría empezar nuevo trabajo antes de un mes
"P7310" = "Busq_trab_primera",# Buscó trabajo por primera vez o había trabajado antes
"P7350" = "Pos_ult_trab", # Posición ocupacional en último trabajo (desocupados)
"P7422" = "Ing_trab_mes_desoc", # Ingresos por trabajo mes pasado (desocupados)
"P7472" = "Ing_trab_mes_desoc2",# Ingresos por trabajo mes pasado (desocupados) - segunda pregunta
"P7495" = "Ing_arriendo_pension", # Ingresos por arriendos y/o pensiones
"P7500s2" = "Ing_pension_jub",# Ingresos por pensiones o jubilaciones
"P7500s3" = "Ing_pension_ali",# Ingresos por pensión alimenticia
"P7505" = "Ing_no_lab_12m", # Ingresos no laborales últimos 12 meses
"P7510s1" = "Ing_din_hog_nac",# Ingresos por dinero de otros hogares en el país
"P7510s2" = "Ing_din_hog_ext",# Ingresos por dinero de otros hogares fuera del país
"P7510s3" = "Ing_ayuda_inst", # Ingresos por ayudas de instituciones
"P7510s5" = "Ing_interes_div",# Ingresos por intereses, dividendos, utilidades
"P7510s6" = "Ing_cesantias",  # Ingresos por cesantías e intereses
"P7510s7" = "Ing_otras_fuentes" # Ingresos de otras fuentes
)
#Aplicar cambios
names(test_personas)[names(test_personas) %in% names(diccionario_personas)] <-
diccionario_personas[names(test_personas)[names(test_personas) %in% names(diccionario_personas)]]
names(train_personas)[names(train_personas) %in% names(diccionario_personas)] <-
diccionario_personas[names(train_personas)[names(train_personas) %in% names(diccionario_personas)]]
#Variables irrelevantes
vars_a_eliminar <- c(
"P6500", "P6510s1", "P6510s2", "P6545s1", "P6545s2",
"P6580s1", "P6580s2", "P6585s1a1", "P6585s1a2", "P6585s2a1",
"P6585s2a2", "P6585s3a1", "P6585s3a2", "P6585s4a1", "P6585s4a2",
"P6590s1", "P6600s1", "P6610s1", "P6620s1", "P6630s1a1",
"P6630s2a1", "P6630s3a1", "P6630s4a1", "P6630s6a1", "P6750",
"P6760", "P550", "P7070", "P7140s1", "P7140s2", "P7422s1", "P7472s1",
"P7500s1", "P7500s1a1","P7500s2a1", "P7500s3a1", "P7510s1a1",
"P7510s2a1", "P7510s3a1","P7510s5a1", "P7510s6a1", "P7510s7a1",
"Cclasnr2", "Cclasnr3", "Cclasnr4", "Cclasnr5", "Cclasnr6", "Cclasnr7", "Cclasnr8", "Cclasnr11"
)
train_personas <- train_personas %>%
select(-all_of(vars_a_eliminar))
variables_finales <- c(
# CLAVES PARA UNIR BASES
"id", "Orden", "Clase", "Dominio", "Fex_c", "Depto", "Fex_dpto",
# VARIABLES PREDICTORAS (solo las que están en AMBOS)
"Oc",                  # Ocupado
"Nivel_educ",          # Nivel educativo
"Edad",                # Edad
"Pos_tra_pri",         # Posición ocupacional
"Cot_pension",         # Cotiza a pensiones
"SS_salud",            # Afiliación salud
"Hras_sem_trab",       # Horas trabajadas
"Jefe_hogar",          # Parentesco
"Act_principal_SP",    # Actividad principal
"T_Tra_Emp",           # Tiempo en empresa
"Ing_HE",              # Ingreso horas extras
"Sub_Trans",           # Subsidio transporte
"Pet",                 # Población edad trabajar
"Ina",                 # Inactivo
"Tam_empresa",         # Tamaño empresa
"Régimen_SS_salud",    # Régimen salud
"Grado_aprobado",      # Grado aprobado
"Sexo",                # Sexo
"Des"                  # Desocupado (agregamos para completar)
)
# Para train_personas
train_personas <- train_personas[, variables_finales]
# Para test_personas (mismas variables)
test_personas <- test_personas[, variables_finales]
table(train_personas$Cot_pension)
# Modificar la función pre_process_personas para recodificar Cot_pension
pre_process_personas <- function(data) {
data <- data |>
mutate(
Sexo = ifelse(Sexo == 2, 1, 0),
Jefe_hogar = ifelse(Jefe_hogar == 1, 1, 0),
Niños = ifelse(Edad <= 6, 1, 0),
Nivel_educ = ifelse(Nivel_educ == 9, 0, Nivel_educ),
Oc = ifelse(is.na(Oc), 0, 1),
Ina = ifelse(is.na(Ina), 0, 1), # 1=Inactivo, 0=Activo (NA→0)
# Nueva recodificación para Cot_pension
Cot_pension = case_when(
Cot_pension == 1 ~ 1,  # Sí cotiza
Cot_pension == 3 ~ 1,  # Ya pensionado, lo tratamos como 1
Cot_pension == 2 ~ 0,  # No cotiza
TRUE ~ 0  # Cualquier otro caso (NA, etc.) → 0
)
)
return(data)
}
# Aplicar el preprocesamiento actualizado
train_personas <- pre_process_personas(train_personas)
test_personas <- pre_process_personas(test_personas)
#Variables de persona agregadas por hogar TRAIN
TR_personas_nivel_hogar <- train_personas |>
group_by(id) |>
summarize(
num_women    = sum(Sexo, na.rm = TRUE),
num_minors   = sum(Niños, na.rm = TRUE),
cat_maxEduc  = max(Nivel_educ, na.rm = TRUE),
num_occupied = sum(Oc, na.rm = TRUE),
# NUEVAS VARIABLES:
num_inactivos = sum(Ina, na.rm = TRUE),  # Total de inactivos
num_cotizantes = sum(Cot_pension, na.rm = TRUE)  # Total que cotizan/pensionados
) |>
ungroup()
##Variables por jefe del hogar Train:
TR_personas_nivel_hogar <- train_personas |>
filter(Jefe_hogar == 1) |>
select(id, Sexo, Nivel_educ, Oc) |>
rename(bin_headWoman = Sexo,
bin_occupiedHead = Oc) |>
left_join(TR_personas_nivel_hogar)
#Variables de persona agregadas por hogar TEST
TE_personas_nivel_hogar <- test_personas |>
group_by(id) |>
summarize(
num_women    = sum(Sexo, na.rm = TRUE),
num_minors   = sum(Niños, na.rm = TRUE),
cat_maxEduc  = max(Nivel_educ, na.rm = TRUE),
num_occupied = sum(Oc, na.rm = TRUE),
# NUEVAS VARIABLES:
num_inactivos = sum(Ina, na.rm = TRUE),  # Total de inactivos
num_cotizantes = sum(Cot_pension, na.rm = TRUE)  # Total que cotizan/pensionados
) |>
ungroup()
##Variables por jefe del hogar Test:
TE_personas_nivel_hogar <- test_personas |>
filter(Jefe_hogar == 1) |>
select(id, Sexo, Nivel_educ, Oc) |>
rename(bin_headWoman = Sexo,
bin_occupiedHead = Oc) |>
left_join(TE_personas_nivel_hogar)
#Arreglos a nivel hogar:
train_hogares <- train_hogares |>
mutate(
bin_rent = ifelse(tiene_vivienda == 3, 1, 0),
prop_cuartos = n_cuartos / Nper,
prop_cuartos_dormir = cuartos_dormir / Nper
) |>
select(id, tiene_vivienda, Pobre, n_cuartos, cuartos_dormir, Nper,
prop_cuartos, prop_cuartos_dormir, bin_rent)
test_hogares <- test_hogares |>
mutate(
bin_rent = ifelse(tiene_vivienda == 3, 1, 0),
prop_cuartos = n_cuartos / Nper,
prop_cuartos_dormir = cuartos_dormir / Nper
) |>
select(id, tiene_vivienda, n_cuartos, cuartos_dormir, Nper,
prop_cuartos, prop_cuartos_dormir, bin_rent)
# Crear las variables de proporción en la unión con hogares:
train <- train_hogares |>
left_join(TR_personas_nivel_hogar) |>
mutate(
# PROPORCIONES EXISTENTES:
prop_inactivos = num_inactivos / Nper,
prop_cotizantes = num_cotizantes / Nper,
prop_ocupados = num_occupied / Nper,
# NUEVA VARIABLE AVANZADA:
vulnerability_index = (
(1 - prop_ocupados) +           # Desempleo
(num_minors / Nper) +           # Carga de menores
(1 - prop_cotizantes) +         # Exclusión financiera
(1 / (prop_cuartos + 0.1))      # Hacinamiento inverso
) / 4                             # Normalizar 0-1
) |>
select(-id) # Solo eliminar en train
test <- test_hogares |>
left_join(TE_personas_nivel_hogar) |>
mutate(
# PROPORCIONES EXISTENTES:
prop_inactivos = num_inactivos / Nper,
prop_cotizantes = num_cotizantes / Nper,
prop_ocupados = num_occupied / Nper,
# NUEVA VARIABLE AVANZADA:
vulnerability_index = (
(1 - prop_ocupados) +           # Desempleo
(num_minors / Nper) +           # Carga de menores
(1 - prop_cotizantes) +         # Exclusión financiera
(1 / (prop_cuartos + 0.1))      # Hacinamiento inverso
) / 4                             # Normalizar 0-1
)
train <- train |>
mutate(prop_ocupados = num_occupied / Nper)
test <- test |>
mutate(prop_ocupados = num_occupied / Nper)
train <- train |>
mutate(Pobre   = factor(Pobre,levels=c(0,1))
)
# Crear nuevas variables basadas en las relaciones más importantes
train_enhanced <- train %>%
mutate(
# Ratios sofisticados (como mencionan en "Feature Refinement")
ratio_efectividad_ocupacional = num_occupied / (num_inactivos + 1),
ratio_proteccion_social = num_cotizantes / (Nper + 1),
indice_capital_humano = (cat_maxEduc * prop_ocupados) / (num_minors + 1),
# Interacciones entre variables top del varImp
interaccion_vivienda_educ = tiene_vivienda * Nivel_educ,
interaccion_cotizantes_ocupados = prop_cotizantes * prop_ocupados,
# Segmentación estratégica
segmento_estrategico = case_when(
prop_cotizantes < 0.2 & num_minors > 1 ~ "familias_vulnerables",
prop_ocupados < 0.3 & vulnerability_index > 0.6 ~ "hogares_criticos",
prop_cotizantes > 0.7 & prop_ocupados > 0.7 ~ "hogares_estables",
TRUE ~ "hogares_medianos"
),
# Variables de desigualdad interna del hogar
dispersion_educativa = cat_maxEduc - Nivel_educ, # Jefe vs máximo
brecha_genero_ocupacion = (num_women / Nper) - prop_ocupados
)
# Convertir segmento a factor
train_enhanced$segmento_estrategico <- factor(train_enhanced$segmento_estrategico)
# Verificar nuevas variables
summary(train_enhanced[, c("ratio_efectividad_ocupacional", "ratio_proteccion_social", "indice_capital_humano")])
# Crear quintiles basados en el índice de vulnerabilidad (como hicieron con income)
train_enhanced <- train_enhanced %>%
mutate(vulnerability_quintile = ntile(vulnerability_index, 5))
# Ver distribución de Pobre por quintil
table(train_enhanced$vulnerability_quintile, train_enhanced$Pobre)
# Estratificar la muestra - tomar misma cantidad por quintil
set.seed(2025)
train_stratified <- train_enhanced %>%
group_by(vulnerability_quintile) %>%
sample_n(min(30000, n())) %>%  # Ajustar según tamaño disponible
ungroup()
# Verificar nuevo balance
table(train_stratified$vulnerability_quintile, train_stratified$Pobre)
# Crear quintiles basados en el índice de vulnerabilidad (como hicieron con income)
train_enhanced <- train_enhanced %>%
mutate(vulnerability_quintile = ntile(vulnerability_index, 5))
# Ver distribución de Pobre por quintil
table(train_enhanced$vulnerability_quintile, train_enhanced$Pobre)
# Estratificar la muestra - tomar misma cantidad por quintil
set.seed(2025)
train_stratified <- train_enhanced %>%
group_by(vulnerability_quintile) %>%
sample_n(min(30000, n())) %>%  # Ajustar según tamaño disponible
ungroup()
# Verificar nuevo balance
table(train_stratified$vulnerability_quintile, train_stratified$Pobre)
# Configuración mejorada con validación
ctrl_xgb_enhanced <- trainControl(
method = "cv",
number = 5,
classProbs = TRUE,
summaryFunction = twoClassSummary,
verboseIter = FALSE,
allowParallel = TRUE,
sampling = "up"  # Upsampling para balancear dentro de folds
)
# Grid de parámetros optimizado
tune_grid_enhanced <- expand.grid(
nrounds = 150,
max_depth = 6,
eta = 0.05,        # Learning rate más bajo
gamma = 1,         # Regularización
colsample_bytree = 0.7,
min_child_weight = 2,
subsample = 0.8
)
# Entrenar modelo mejorado
set.seed(2025)
model_xgb_enhanced <- train(
Pobre ~ .,
data = train_stratified %>% select(-vulnerability_quintile),
method = "xgbTree",
trControl = ctrl_xgb_enhanced,
tuneGrid = tune_grid_enhanced,
metric = "ROC",
verbose = FALSE
)
train$Pobre <- factor(ifelse(train$Pobre == 1, "Pobre", "NoPobre"),
levels = c("NoPobre", "Pobre"))
model_xgb_enhanced <- train(
Pobre ~ .,
data = train_stratified %>% select(-vulnerability_quintile),
method = "xgbTree",
trControl = ctrl_xgb_enhanced,
tuneGrid = tune_grid_enhanced,
metric = "ROC",
verbose = FALSE
)
train_stratified$Pobre <- factor(ifelse(train$Pobre == 1, "Pobre", "NoPobre"),
levels = c("NoPobre", "Pobre"))
# Corregir los niveles del factor Pobre
train_stratified$Pobre <- factor(train_stratified$Pobre,
levels = c(0, 1),
labels = c("NoPobre", "Pobre"))
# Verificar
table(train_stratified$Pobre)
levels(train_stratified$Pobre)
# Ahora ejecutar el modelo
set.seed(2025)
model_xgb_enhanced <- train(
Pobre ~ .,
data = train_stratified %>% select(-vulnerability_quintile),
method = "xgbTree",
trControl = ctrl_xgb_enhanced,
tuneGrid = tune_grid_enhanced,
metric = "ROC",
verbose = FALSE
)
# Obtener probabilidades del modelo mejorado
probabilidades_enhanced <- predict(model_xgb_enhanced, train_stratified, type = "prob")
# Función para evaluar por quintiles
evaluar_por_quintiles <- function(probs, true_labels, vulnerability_quintiles, threshold = 0.3) {
predictions <- ifelse(probs$Pobre > threshold, "Pobre", "NoPobre")
results <- data.frame(
quintil = vulnerability_quintiles,
verdadero = true_labels,
prediccion = predictions
)
confusion_por_quintil <- results %>%
group_by(quintil) %>%
summarise(
accuracy = mean(prediccion == verdadero),
recall_pobre = sum(prediccion == "Pobre" & verdadero == "Pobre") / sum(verdadero == "Pobre"),
precision_pobre = sum(prediccion == "Pobre" & verdadero == "Pobre") / sum(prediccion == "Pobre"),
n_pobres_reales = sum(verdadero == "Pobre"),
n_pobres_predichos = sum(prediccion == "Pobre")
)
return(confusion_por_quintil)
}
# Evaluar con threshold 0.3
resultados_quintiles <- evaluar_por_quintiles(
probabilidades_enhanced,
train_stratified$Pobre,
train_stratified$vulnerability_quintile
)
print(resultados_quintiles)
# Crear ensemble
crear_ensemble <- function(probs, thresholds = c(0.2, 0.3, 0.4)) {
ensemble_score <- rowMeans(sapply(thresholds, function(th) {
ifelse(probs$Pobre > th, 1, 0)
}))
return(ensemble_score)
}
ensemble_scores <- crear_ensemble(probabilidades_enhanced)
# Encontrar mejor threshold para ensemble
encontrar_mejor_threshold_ensemble <- function(ensemble_scores, true_labels) {
thresholds <- seq(0.1, 0.6, by = 0.05)
resultados <- data.frame()
for(th in thresholds) {
pred_temp <- ifelse(ensemble_scores > th, "Pobre", "NoPobre")
cm_temp <- confusionMatrix(factor(pred_temp, levels = c("NoPobre", "Pobre")), true_labels)
resultados <- rbind(resultados, data.frame(
threshold = th,
recall_pobre = cm_temp$byClass["Sensitivity"],
precision_pobre = cm_temp$byClass["Pos Pred Value"],
f1_pobre = cm_temp$byClass["F1"]
))
}
return(resultados)
}
resultados_ensemble <- encontrar_mejor_threshold_ensemble(ensemble_scores, train_stratified$Pobre)
print(resultados_ensemble)
# Preparar test set con las mismas features
test_enhanced <- test %>%
mutate(
ratio_efectividad_ocupacional = num_occupied / (num_inactivos + 1),
ratio_proteccion_social = num_cotizantes / (Nper + 1),
indice_capital_humano = (cat_maxEduc * prop_ocupados) / (num_minors + 1),
interaccion_vivienda_educ = tiene_vivienda * Nivel_educ,
interaccion_cotizantes_ocupados = prop_cotizantes * prop_ocupados,
segmento_estrategico = case_when(
prop_cotizantes < 0.2 & num_minors > 1 ~ "familias_vulnerables",
prop_ocupados < 0.3 & vulnerability_index > 0.6 ~ "hogares_criticos",
prop_cotizantes > 0.7 & prop_ocupados > 0.7 ~ "hogares_estables",
TRUE ~ "hogares_medianos"
),
dispersion_educativa = cat_maxEduc - Nivel_educ,
brecha_genero_ocupacion = (num_women / Nper) - prop_ocupados
)
test_enhanced$segmento_estrategico <- factor(test_enhanced$segmento_estrategico)
# Obtener probabilidades del test
probabilidades_test <- predict(model_xgb_enhanced, test_enhanced, type = "prob")
# Aplicar ensemble con mejor threshold (0.35)
ensemble_test <- crear_ensemble(probabilidades_test, thresholds = c(0.2, 0.3, 0.4))
predicciones_finales <- ifelse(ensemble_test > 0.35, 1, 0)
# Submission final
submission_final <- data.frame(
id = test$id,
poverty = predicciones_finales
)
write.csv(submission_final, "C:/Users/Marlon Angulo/Downloads/XGB_enhanced_ensemble_0.77F1.csv", row.names = FALSE)
# Tu modelo original que dio 0.65 - pero con las nuevas features
set.seed(2025)
model_original_enhanced <- train(
Pobre ~ .,
data = train,  # Usar TODOS los datos, no solo estratificados
method = "xgbTree",
trControl = trainControl(method = "cv", number = 3, classProbs = TRUE),
tuneGrid = expand.grid(
nrounds = 100,
max_depth = 6,
eta = 0.1,
gamma = 0,
colsample_bytree = 0.8,
min_child_weight = 1,
subsample = 0.8
),
verbose = FALSE
)
# Probar en test
prob_original <- predict(model_original_enhanced, test_enhanced, type = "prob")
pred_original <- ifelse(prob_original$Pobre > 0.3, 1, 0)
submission_original <- data.frame(id = test$id, poverty = pred_original)
write.csv(submission_original, "C:/Users/Marlon Angulo/Downloads/XGB_original_enhanced.csv", row.names = FALSE)
prob_train_enhanced <- predict(model_original_enhanced, train, type = "prob")
pred_train_enhanced <- ifelse(prob_train_enhanced$Pobre > 0.3, "Pobre", "NoPobre")
pred_train_enhanced <- factor(pred_train_enhanced, levels = c("NoPobre", "Pobre"))
confusion_train_enhanced <- confusionMatrix(pred_train_enhanced, train$Pobre)
print(confusion_train_enhanced)
# Función F1 corregida y robusta
f1_summary <- function(data, lev = NULL, model = NULL) {
# Asegurar mismos niveles
data$pred <- factor(data$pred, levels = lev)
data$obs <- factor(data$obs, levels = lev)
confusion <- caret::confusionMatrix(data$pred, data$obs)
# Calcular F1 específicamente para la clase "Pobre"
tp <- confusion$table[2, 2]  # True Positives (Pobre -> Pobre)
fp <- confusion$table[2, 1]  # False Positives (NoPobre -> Pobre)
fn <- confusion$table[1, 2]  # False Negatives (Pobre -> NoPobre)
precision <- tp / (tp + fp)
recall <- tp / (tp + fn)
f1 <- 2 * (precision * recall) / (precision + recall)
# Manejar divisiones por cero
if(is.na(f1)) f1 <- 0
c(F1 = f1,
Precision = precision,
Recall = recall,
Accuracy = confusion$overall["Accuracy"])
}
# Configuración optimizada para F1
ctrl_f1_optimized <- trainControl(
method = "cv",
number = 5,
classProbs = TRUE,
summaryFunction = f1_summary,
verboseIter = FALSE,
allowParallel = TRUE
)
# Entrenar modelo optimizado para F1
set.seed(2025)
model_f1_optimized <- train(
Pobre ~ .,
data = train,
method = "xgbTree",
trControl = ctrl_f1_optimized,
metric = "F1",  # Optimizar directamente para F1
maximize = TRUE,
tuneGrid = expand.grid(
nrounds = 100,
max_depth = 6,
eta = 0.1,
gamma = 0,
colsample_bytree = 0.8,
min_child_weight = 1,
subsample = 0.8
),
verbose = FALSE
)
# Ver resultados F1 en CV
print(model_f1_optimized)
cat("Mejor F1 en CV:", max(model_f1_optimized$results$F1), "\n")
# Matriz de confusión con threshold 0.3
prob_f1_train <- predict(model_f1_optimized, train, type = "prob")
pred_f1_train <- ifelse(prob_f1_train$Pobre > 0.3, "Pobre", "NoPobre")
pred_f1_train <- factor(pred_f1_train, levels = c("NoPobre", "Pobre"))
confusion_f1_train <- confusionMatrix(pred_f1_train, train$Pobre)
print(confusion_f1_train)
cat("F1 en Train:", confusion_f1_train$byClass["F1"], "\n")
# Exportar submission
prob_f1_test <- predict(model_f1_optimized, test_enhanced, type = "prob")
pred_f1_test <- ifelse(prob_f1_test$Pobre > 0.3, 1, 0)
submission_f1 <- data.frame(id = test$id, poverty = pred_f1_test)
write.csv(submission_f1, "C:/Users/Marlon Angulo/Downloads/XGB_F1_optimized.csv", row.names = FALSE)
